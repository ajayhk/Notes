Glossary

Sigmoid:
  sigmoid(x) = 1/(1+e^x)
  Sigmoid bounds the output x between 0 and 1 and is useful for probabilities and other
  values that need to be bounded between 0 and 1
Linear regression:
  Model relationship between one or more independent variables and a dependent scalar
  If only one input variable, then simple linear regression, else multiple linear regression
  Simple linear regression is useful for finding relationship between two continuous variables
  Multivariate linear regression is where multiple coorelated dependent variables are predicted
Logistic regression:
  Models the probability of certain classes or events existing. Binary is when there are only two classes
  For more than two, each class is assigned a probability score and the sum of probabilities adds to 1
  Sigmoid is usually used for such functions as that stays between 0 and 1
  yhat = sigmoid (wt*x + b)
Loss function:
  Loss function is a function of difference between expected and actual prediction. Loss (yhat, y)
  MSE doesnt work well with gradient descent for Logistic regression
  So use L(yhat, y) = -(y.log(yhat) + (1-y).log(1-yhat))
  If y=1, L = -log(yhat), so yhat should be as large as possible, close to 1 since sigmoid taken
  If y=0, L = log(1-yhat), so yhat should be as close to 0 as possible
Cost function:
  Usually average of the above loss functions + regularization etc.
Cross-entropy loss:
  Log loss between 0 and 1. When the true prediction is 1 and the actual prediction
  is lower, as the actual prediction gets closer to 0, the loss increases exponentially
def CrossEntropy(yHat, y):
    if y == 1: # if true prediction is positive
      return -log(yHat) # decrease loss the closer the prediction is to 1
    else:
      return -log(1 - yHat) # increase loss if prediction goes to 1
Object detection:
  Finding objects of interest in an image
Bounding boxes:
  Boxes drawn around objects of interest
  Each bounding box also has a classification probability associated
  that predicts the likelyhood of classes
Confidence score:
  Bounding boxes also have a confidence score associated that says
  how likely this box contains an (any) object
NMS:
  Boxes whose confidence score is low (below a certain threshold) can
  be filtered out to avoid too many bounding boxes to process. This is
  called Non-Max Supression (NMS)
Multistage detector:
  First stage, a region proposal is created of regions that may contain objects
  Second stage, prediction done for these regions. E.g. Faster R-CNN
Onestage detector:
  Single pass and predicts all bounding boxes in one go. E.g. Yolo, SSD
IOU (Intersection over Union) aka Jaccard index:
  Area of overlap / Area of union



Neural networks
Moving from sigmoid to Relu helps gradient descent train faster because
sigmoid had really flat slopes at the ends that made training really slow



Object Detection:

Classifiers do not work well when there are multiple objects in the image
Object detectors predicts bounding boxes for each image and so can better predict the image
Bounding boxes require four additional numbers for each of the corners
Object detectors have two outputs
1. The usual classification prediction
2. Bounding box regression
Thus the loss function is an addition of the regression loss for bounding box (usually MSE)
and cross-entropy loss for classification
Bounding boxes need to specialize to only handle one object. Otherwise they will end up taking
the average of all objects and fail. Hence each detector is assigned a specific position in image
For that, a grid is created and each detector focuses on only one cell in the grid
There can be multiple detectors for each grid, with each grid focusing on image of different sizes
For example, one detector might be for a square object bb, one for a long object and one for a wide object
A detector is responsible for detecting an image only if the center of the image lies in the grid
that the detector owns. This prevents multiple detectors of different grids competing to detect one object
Yolov3 has three grids of sizes 13x13, 19x19
Yolov3 detector outputs 85 numbers, 80 for the class probabilities, 4 for bounding box coordinates and
one for confidence score (that an object exists for that bounding box)
If there are 5 detectors, there would be 5*85 channels = 425 channels
If a grid ix 13x13, and 5 detectors, then there would be 13x13x5=845 predictions
To avoid too many predictions, the confidence score (object likely?) is used to remove most predictions
NMS removes all boxes that overlap (beyond a certain threshold called nms threshold) with the box
that has the highest confidence
At the end of these two, there would be around 10 predictions out of possible 845
Anchors refer to the 5 box sizes (square, long wide etc.) which map to each detector
Thus there will be as many anchors as detectors and detectors map 1:1 to anchors






